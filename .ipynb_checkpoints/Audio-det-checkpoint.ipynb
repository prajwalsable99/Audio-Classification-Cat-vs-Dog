{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449151f8-21bf-4cbd-a5cb-c1e1db9d0721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aaedcbe-c904-42e8-8818-e7c9405fd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3beb2650-80c3-4ee4-adc6-11e517e24165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(duration=5, fs=22050):\n",
    "   print(\"Recording...\")\n",
    "   audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float64')\n",
    "   # print(audio)\n",
    "   sd.wait()  # Wait until the recording is finished\n",
    "   print(\"Recording finished\")\n",
    "   print(\"playing audio\")\n",
    "   \n",
    "   sd.play(audio,fs)\n",
    "   sd.wait()\n",
    "   print(\"playing finished\")\n",
    "   return np.squeeze(audio)\n",
    " \n",
    "# Function to extract MFCC features from audio\n",
    "def extract_features(audio, sr=22050):\n",
    "   mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "   return np.mean(mfccs.T, axis=0)\n",
    " \n",
    "# Load your pre-trained models (for example purposes, we'll define models here)\n",
    "# In a real-world scenario, you would load pre-trained models using joblib or TensorFlow\n",
    "def load_gender_model():\n",
    "   model = SVC(kernel='linear')\n",
    "   # Assume model has been trained, so we'll just return it\n",
    "   return model\n",
    " \n",
    "def load_health_model():\n",
    "   model = Sequential([\n",
    "       Dense(256, activation='relu', input_shape=(40,)),\n",
    "       Dropout(0.3),\n",
    "       Dense(128, activation='relu'),\n",
    "       Dropout(0.3),\n",
    "       Dense(64, activation='relu'),\n",
    "       Dense(2, activation='softmax')  # Assuming binary classification for health status\n",
    "   ])\n",
    "   model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   # Assume model has been trained, so we'll just return it\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bc68958-34ea-45bc-8667-bf52c5546994",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 40)  # 100 samples with 40 MFCC features each\n",
    "y_gender = np.random.choice(['male', 'female'], 100)  # Random gender labels\n",
    "y_health = np.random.choice(['healthy', 'unhealthy'], 100)  # Random health labels\n",
    " \n",
    "# Encode labels\n",
    "le_gender = LabelEncoder()\n",
    "y_gender_encoded = le_gender.fit_transform(y_gender)\n",
    " \n",
    "le_health = LabelEncoder()\n",
    "y_health_encoded = le_health.fit_transform(y_health)\n",
    " \n",
    "# Split the dataset into training and testing\n",
    "X_train, X_test, y_gender_train, y_gender_test = train_test_split(X, y_gender_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_health_train, y_health_test = train_test_split(X, y_health_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a212216e-4aef-4084-846e-fa0e0c4abfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5092 - loss: 0.6948\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4937 - loss: 0.7110 \n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5352 - loss: 0.6847 \n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.6399 \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7662 - loss: 0.5911\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 0.6509 \n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.6623 \n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.6395 \n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6920 - loss: 0.5968 \n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7166 - loss: 0.6079 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Gender Classification Accuracy: 50.00%\n",
      "Health Status Detection Accuracy: 35.00%\n"
     ]
    }
   ],
   "source": [
    "gender_model = load_gender_model()\n",
    "gender_model.fit(X_train, y_gender_train)\n",
    " \n",
    "# Train health status detection model\n",
    "health_model = load_health_model()\n",
    "health_model.fit(X_train, y_health_train, epochs=10, batch_size=8, verbose=1)\n",
    " \n",
    "# Evaluate the models\n",
    "y_gender_pred = gender_model.predict(X_test)\n",
    "y_health_pred = np.argmax(health_model.predict(X_test), axis=1)\n",
    " \n",
    "gender_accuracy = accuracy_score(y_gender_test, y_gender_pred)\n",
    "health_accuracy = accuracy_score(y_health_test, y_health_pred)\n",
    " \n",
    "print(f\"Gender Classification Accuracy: {gender_accuracy * 100:.2f}%\")\n",
    "print(f\"Health Status Detection Accuracy: {health_accuracy * 100:.2f}%\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67b25d4b-8379-48ab-b51b-df06de796d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished\n",
      "playing audio\n",
      "playing finished\n",
      "Predicted Gender: male\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Predicted Health Status: healthy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    " \n",
    "# Example dataset for training (replace with actual dataset)\n",
    "# X is the feature array, y_gender is the gender labels, y_health is the health status labels\n",
    "# X, y_gender, y_health = your_data_loading_function()\n",
    " \n",
    "# For example purposes, we'll generate random data\n",
    "\n",
    " \n",
    "# Train gender classification model\n",
    "\n",
    "# Real-time voice processing\n",
    "audio = record_audio()\n",
    "features = extract_features(audio)\n",
    "\n",
    "features=np.array([features])\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Predict gender\n",
    "gender_prediction = gender_model.predict(features)\n",
    "predicted_gender = le_gender.inverse_transform(gender_prediction)[0]\n",
    "print(f\"Predicted Gender: {predicted_gender}\")\n",
    " \n",
    "# Predict health status\n",
    "health_prediction = np.argmax(health_model.predict(features), axis=1)\n",
    "predicted_health = le_health.inverse_transform(health_prediction)[0]\n",
    "print(f\"Predicted Health Status: {predicted_health}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe0549-cd9a-4ef2-94c1-52f372549f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c617d44-e8f6-43fb-aa2a-af4205d05006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dea36-679b-41bf-bb6b-9000118160f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df045b25-fb4d-4eda-a221-db7432fc5e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
